import streamlit as st
import joblib
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk

nltk.download('stopwords')
nltk.download('wordnet')

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
model = joblib.load("models/sentiment_model.pkl")

# ØªØ§Ø¨Ø¹ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    text = re.sub(r"[^a-zA-Z\s]", "", text.lower())
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]
    return " ".join(tokens)

# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø§ Streamlit
st.title("ğŸ§  Sentiment Analyzer")
st.write("Ø§ÛŒÙ† ÛŒÚ© Ø§Ø¨Ø²Ø§Ø± Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù†Ø¸Ø±Ø§Øª Ù…ØªÙ†ÛŒ Ø§Ø³Øª.")

user_input = st.text_area("Ù…ØªÙ† Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")

if st.button("ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³"):
    cleaned = clean_text(user_input)
    prediction = model.predict([cleaned])[0]
    label = "Ù…Ø«Ø¨Øª ğŸ˜Š" if prediction == 1 else "Ù…Ù†ÙÛŒ ğŸ˜"
    st.success(f"Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„: **{label}**")
